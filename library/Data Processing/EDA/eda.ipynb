{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis (EDA) Without Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Usual Data Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## **1️⃣ Importing Necessary Libraries**\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import seaborn as sns  \n",
    "from scipy.stats import zscore  \n",
    "\n",
    "## **2️⃣ Loading the Titanic Dataset**\n",
    "# Using seaborn's built-in Titanic dataset  \n",
    "df = sns.load_dataset('titanic')  \n",
    "\n",
    "## **3️⃣ Basic Dataset Information**\n",
    "# Display first 5 rows  \n",
    "print(\"First 5 Rows:\\n\", df.head())  \n",
    "\n",
    "# Display last 5 rows  \n",
    "print(\"Last 5 Rows:\\n\", df.tail())  \n",
    "\n",
    "# Dataset shape  \n",
    "print(\"Dataset Shape:\", df.shape)  \n",
    "\n",
    "# Column names and data types  \n",
    "print(\"Column Information:\\n\")  \n",
    "df.info()  \n",
    "\n",
    "## **4️⃣ Handling Missing Values**\n",
    "# Checking for missing values  \n",
    "print(\"\\nMissing Values Per Column:\\n\", df.isnull().sum())  \n",
    "\n",
    "# Filling missing values for numerical columns with median  \n",
    "df['age'].fillna(df['age'].median(), inplace=True)  \n",
    "\n",
    "# Filling missing values for categorical columns with mode  \n",
    "df['embark_town'].fillna(df['embark_town'].mode()[0], inplace=True)  \n",
    "\n",
    "# Dropping columns with too many missing values  \n",
    "df.drop(columns=['deck'], inplace=True)  \n",
    "\n",
    "## **5️⃣ Handling Duplicates**\n",
    "# Checking for duplicate rows  \n",
    "print(\"\\nTotal Duplicate Rows:\", df.duplicated().sum())  \n",
    "\n",
    "# Removing duplicates  \n",
    "df = df.drop_duplicates() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6️⃣ Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics (Numerical):\n",
      "          survived      pclass         age       sibsp       parch        fare\n",
      "count  775.000000  775.000000  775.000000  775.000000  775.000000  775.000000\n",
      "mean     0.412903    2.246452   29.581187    0.529032    0.420645   34.878403\n",
      "std      0.492674    0.853574   13.766359    0.990326    0.840565   52.408474\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    1.000000   21.000000    0.000000    0.000000    8.050000\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   15.900000\n",
      "75%      1.000000    3.000000   36.000000    1.000000    1.000000   34.197900\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "Summary Statistics (Categorical):\n",
      "          sex embarked  who  embark_town alive\n",
      "count    775      773  775          775   775\n",
      "unique     2        3    3            3     2\n",
      "top     male        S  man  Southampton    no\n",
      "freq     483      560  443          562   455\n"
     ]
    }
   ],
   "source": [
    "# Displaying summary statistics for numerical columns  \n",
    "print(\"\\nSummary Statistics (Numerical):\\n\", df.describe())  \n",
    "\n",
    "# Displaying summary statistics for categorical columns  \n",
    "print(\"\\nSummary Statistics (Categorical):\\n\", df.describe(include=['O']))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7️⃣ Feature Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in sex:\n",
      " sex\n",
      "male      483\n",
      "female    292\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Values in embark_town:\n",
      " embark_town\n",
      "Southampton    562\n",
      "Cherbourg      155\n",
      "Queenstown      58\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Values in class:\n",
      " class\n",
      "Third     401\n",
      "First     210\n",
      "Second    164\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Values in who:\n",
      " who\n",
      "man      443\n",
      "woman    250\n",
      "child     82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Values in alive:\n",
      " alive\n",
      "no     455\n",
      "yes    320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "age Percentiles:\n",
      " 0.01     1.00\n",
      "0.25    21.00\n",
      "0.50    28.00\n",
      "0.75    36.00\n",
      "0.99    65.26\n",
      "Name: age, dtype: float64\n",
      "\n",
      "fare Percentiles:\n",
      " 0.01      0.0000\n",
      "0.25      8.0500\n",
      "0.50     15.9000\n",
      "0.75     34.1979\n",
      "0.99    262.3750\n",
      "Name: fare, dtype: float64\n",
      "\n",
      "sibsp Percentiles:\n",
      " 0.01    0.0\n",
      "0.25    0.0\n",
      "0.50    0.0\n",
      "0.75    1.0\n",
      "0.99    4.0\n",
      "Name: sibsp, dtype: float64\n",
      "\n",
      "parch Percentiles:\n",
      " 0.01    0.0\n",
      "0.25    0.0\n",
      "0.50    0.0\n",
      "0.75    1.0\n",
      "0.99    4.0\n",
      "Name: parch, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking unique values in categorical features  \n",
    "categorical_features = ['sex', 'embark_town', 'class', 'who', 'alive']  \n",
    "for col in categorical_features:  \n",
    "    print(f\"\\nUnique Values in {col}:\\n\", df[col].value_counts())  \n",
    "\n",
    "# Checking range and percentiles for numerical features  \n",
    "numerical_features = ['age', 'fare', 'sibsp', 'parch']  \n",
    "for col in numerical_features:  \n",
    "    print(f\"\\n{col} Percentiles:\\n\", df[col].quantile([0.01, 0.25, 0.5, 0.75, 0.99]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8️⃣ Feature Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix:\n",
      "                          survived    pclass       age     sibsp     parch  \\\n",
      "survived                 1.000000 -0.331388 -0.078114 -0.037841  0.069864   \n",
      "pclass                  -0.331388  1.000000 -0.342745  0.087050  0.038998   \n",
      "age                     -0.078114 -0.342745  1.000000 -0.279316 -0.182697   \n",
      "sibsp                   -0.037841  0.087050 -0.279316  1.000000  0.379535   \n",
      "parch                    0.069864  0.038998 -0.182697  0.379535  1.000000   \n",
      "fare                     0.247159 -0.554649  0.092503  0.133807  0.190823   \n",
      "adult_male              -0.529158  0.069762  0.274454 -0.272326 -0.345630   \n",
      "alone                   -0.176714  0.113778  0.190270 -0.607809 -0.569387   \n",
      "sex_male                -0.516121  0.118507  0.093574 -0.095574 -0.235116   \n",
      "embarked_Q              -0.039325  0.211009 -0.031798 -0.003388 -0.066534   \n",
      "embarked_S              -0.135950  0.108069 -0.021726  0.063312  0.063260   \n",
      "embarked_nan             0.060654 -0.074326  0.075495 -0.027190 -0.025471   \n",
      "class_Second             0.098065 -0.149683  0.007926 -0.047118  0.003814   \n",
      "class_Third             -0.322933  0.914717 -0.295786  0.093558  0.031727   \n",
      "who_man                 -0.529158  0.069762  0.274454 -0.272326 -0.345630   \n",
      "who_woman                0.480870 -0.173484  0.090227  0.013225  0.137479   \n",
      "embark_town_Queenstown  -0.039325  0.211009 -0.031798 -0.003388 -0.066534   \n",
      "embark_town_Southampton -0.129450  0.099935 -0.013210  0.060405  0.060548   \n",
      "alive_yes                1.000000 -0.331388 -0.078114 -0.037841  0.069864   \n",
      "\n",
      "                             fare  adult_male     alone  sex_male  embarked_Q  \\\n",
      "survived                 0.247159   -0.529158 -0.176714 -0.516121   -0.039325   \n",
      "pclass                  -0.554649    0.069762  0.113778  0.118507    0.211009   \n",
      "age                      0.092503    0.274454  0.190270  0.093574   -0.031798   \n",
      "sibsp                    0.133807   -0.272326 -0.607809 -0.095574   -0.003388   \n",
      "parch                    0.190823   -0.345630 -0.569387 -0.235116   -0.066534   \n",
      "fare                     1.000000   -0.164481 -0.245168 -0.168979   -0.109681   \n",
      "adult_male              -0.164481    1.000000  0.384923  0.898154   -0.051070   \n",
      "alone                   -0.245168    0.384923  1.000000  0.277339    0.082030   \n",
      "sex_male                -0.168979    0.898154  0.277339  1.000000   -0.041967   \n",
      "embarked_Q              -0.109681   -0.051070  0.082030 -0.041967    1.000000   \n",
      "embarked_S              -0.186410    0.092582  0.024596  0.107014   -0.459017   \n",
      "embarked_nan             0.043822   -0.058757  0.044735 -0.065420   -0.014467   \n",
      "class_Second            -0.128487   -0.068592 -0.041247 -0.066555   -0.111335   \n",
      "class_Third             -0.420903    0.087579  0.113971  0.128352    0.225607   \n",
      "who_man                 -0.164481    1.000000  0.384923  0.898154   -0.051070   \n",
      "who_woman                0.182446   -0.797119 -0.183503 -0.887508    0.065986   \n",
      "embark_town_Queenstown  -0.109681   -0.051070  0.082030 -0.041967    1.000000   \n",
      "embark_town_Southampton -0.181970    0.086173  0.029751  0.099889   -0.461990   \n",
      "alive_yes                0.247159   -0.529158 -0.176714 -0.516121   -0.039325   \n",
      "\n",
      "                         embarked_S  embarked_nan  class_Second  class_Third  \\\n",
      "survived                  -0.135950      0.060654      0.098065    -0.322933   \n",
      "pclass                     0.108069     -0.074326     -0.149683     0.914717   \n",
      "age                       -0.021726      0.075495      0.007926    -0.295786   \n",
      "sibsp                      0.063312     -0.027190     -0.047118     0.093558   \n",
      "parch                      0.063260     -0.025471      0.003814     0.031727   \n",
      "fare                      -0.186410      0.043822     -0.128487    -0.420903   \n",
      "adult_male                 0.092582     -0.058757     -0.068592     0.087579   \n",
      "alone                      0.024596      0.044735     -0.041247     0.113971   \n",
      "sex_male                   0.107014     -0.065420     -0.066555     0.128352   \n",
      "embarked_Q                -0.459017     -0.014467     -0.111335     0.225607   \n",
      "embarked_S                 1.000000     -0.082092      0.179900     0.018716   \n",
      "embarked_nan              -0.082092      1.000000     -0.026353    -0.052670   \n",
      "class_Second               0.179900     -0.026353      1.000000    -0.536460   \n",
      "class_Third                0.018716     -0.052670     -0.536460     1.000000   \n",
      "who_man                    0.092582     -0.058757     -0.068592     0.087579   \n",
      "who_woman                 -0.102619      0.073711      0.061475    -0.173200   \n",
      "embark_town_Queenstown    -0.459017     -0.014467     -0.111335     0.225607   \n",
      "embark_town_Southampton    0.993565      0.031315      0.177426     0.012785   \n",
      "alive_yes                 -0.135950      0.060654      0.098065    -0.322933   \n",
      "\n",
      "                          who_man  who_woman  embark_town_Queenstown  \\\n",
      "survived                -0.529158   0.480870               -0.039325   \n",
      "pclass                   0.069762  -0.173484                0.211009   \n",
      "age                      0.274454   0.090227               -0.031798   \n",
      "sibsp                   -0.272326   0.013225               -0.003388   \n",
      "parch                   -0.345630   0.137479               -0.066534   \n",
      "fare                    -0.164481   0.182446               -0.109681   \n",
      "adult_male               1.000000  -0.797119               -0.051070   \n",
      "alone                    0.384923  -0.183503                0.082030   \n",
      "sex_male                 0.898154  -0.887508               -0.041967   \n",
      "embarked_Q              -0.051070   0.065986                1.000000   \n",
      "embarked_S               0.092582  -0.102619               -0.459017   \n",
      "embarked_nan            -0.058757   0.073711               -0.014467   \n",
      "class_Second            -0.068592   0.061475               -0.111335   \n",
      "class_Third              0.087579  -0.173200                0.225607   \n",
      "who_man                  1.000000  -0.797119               -0.051070   \n",
      "who_woman               -0.797119   1.000000                0.065986   \n",
      "embark_town_Queenstown  -0.051070   0.065986                1.000000   \n",
      "embark_town_Southampton  0.086173  -0.094539               -0.461990   \n",
      "alive_yes               -0.529158   0.480870               -0.039325   \n",
      "\n",
      "                         embark_town_Southampton  alive_yes  \n",
      "survived                               -0.129450   1.000000  \n",
      "pclass                                  0.099935  -0.331388  \n",
      "age                                    -0.013210  -0.078114  \n",
      "sibsp                                   0.060405  -0.037841  \n",
      "parch                                   0.060548   0.069864  \n",
      "fare                                   -0.181970   0.247159  \n",
      "adult_male                              0.086173  -0.529158  \n",
      "alone                                   0.029751  -0.176714  \n",
      "sex_male                                0.099889  -0.516121  \n",
      "embarked_Q                             -0.461990  -0.039325  \n",
      "embarked_S                              0.993565  -0.135950  \n",
      "embarked_nan                            0.031315   0.060654  \n",
      "class_Second                            0.177426   0.098065  \n",
      "class_Third                             0.012785  -0.322933  \n",
      "who_man                                 0.086173  -0.529158  \n",
      "who_woman                              -0.094539   0.480870  \n",
      "embark_town_Queenstown                 -0.461990  -0.039325  \n",
      "embark_town_Southampton                 1.000000  -0.129450  \n",
      "alive_yes                              -0.129450   1.000000  \n",
      "\n",
      "Highly Correlated Features (Correlation > 0.5):\n",
      "                          survived    pclass  age     sibsp     parch  \\\n",
      "survived                 1.000000       NaN  NaN       NaN       NaN   \n",
      "pclass                        NaN  1.000000  NaN       NaN       NaN   \n",
      "age                           NaN       NaN  1.0       NaN       NaN   \n",
      "sibsp                         NaN       NaN  NaN  1.000000       NaN   \n",
      "parch                         NaN       NaN  NaN       NaN  1.000000   \n",
      "fare                          NaN  0.554649  NaN       NaN       NaN   \n",
      "adult_male               0.529158       NaN  NaN       NaN       NaN   \n",
      "alone                         NaN       NaN  NaN  0.607809  0.569387   \n",
      "sex_male                 0.516121       NaN  NaN       NaN       NaN   \n",
      "embarked_Q                    NaN       NaN  NaN       NaN       NaN   \n",
      "embarked_S                    NaN       NaN  NaN       NaN       NaN   \n",
      "embarked_nan                  NaN       NaN  NaN       NaN       NaN   \n",
      "class_Second                  NaN       NaN  NaN       NaN       NaN   \n",
      "class_Third                   NaN  0.914717  NaN       NaN       NaN   \n",
      "who_man                  0.529158       NaN  NaN       NaN       NaN   \n",
      "who_woman                     NaN       NaN  NaN       NaN       NaN   \n",
      "embark_town_Queenstown        NaN       NaN  NaN       NaN       NaN   \n",
      "embark_town_Southampton       NaN       NaN  NaN       NaN       NaN   \n",
      "alive_yes                1.000000       NaN  NaN       NaN       NaN   \n",
      "\n",
      "                             fare  adult_male     alone  sex_male  embarked_Q  \\\n",
      "survived                      NaN    0.529158       NaN  0.516121         NaN   \n",
      "pclass                   0.554649         NaN       NaN       NaN         NaN   \n",
      "age                           NaN         NaN       NaN       NaN         NaN   \n",
      "sibsp                         NaN         NaN  0.607809       NaN         NaN   \n",
      "parch                         NaN         NaN  0.569387       NaN         NaN   \n",
      "fare                     1.000000         NaN       NaN       NaN         NaN   \n",
      "adult_male                    NaN    1.000000       NaN  0.898154         NaN   \n",
      "alone                         NaN         NaN  1.000000       NaN         NaN   \n",
      "sex_male                      NaN    0.898154       NaN  1.000000         NaN   \n",
      "embarked_Q                    NaN         NaN       NaN       NaN         1.0   \n",
      "embarked_S                    NaN         NaN       NaN       NaN         NaN   \n",
      "embarked_nan                  NaN         NaN       NaN       NaN         NaN   \n",
      "class_Second                  NaN         NaN       NaN       NaN         NaN   \n",
      "class_Third                   NaN         NaN       NaN       NaN         NaN   \n",
      "who_man                       NaN    1.000000       NaN  0.898154         NaN   \n",
      "who_woman                     NaN    0.797119       NaN  0.887508         NaN   \n",
      "embark_town_Queenstown        NaN         NaN       NaN       NaN         1.0   \n",
      "embark_town_Southampton       NaN         NaN       NaN       NaN         NaN   \n",
      "alive_yes                     NaN    0.529158       NaN  0.516121         NaN   \n",
      "\n",
      "                         embarked_S  embarked_nan  class_Second  class_Third  \\\n",
      "survived                        NaN           NaN           NaN          NaN   \n",
      "pclass                          NaN           NaN           NaN     0.914717   \n",
      "age                             NaN           NaN           NaN          NaN   \n",
      "sibsp                           NaN           NaN           NaN          NaN   \n",
      "parch                           NaN           NaN           NaN          NaN   \n",
      "fare                            NaN           NaN           NaN          NaN   \n",
      "adult_male                      NaN           NaN           NaN          NaN   \n",
      "alone                           NaN           NaN           NaN          NaN   \n",
      "sex_male                        NaN           NaN           NaN          NaN   \n",
      "embarked_Q                      NaN           NaN           NaN          NaN   \n",
      "embarked_S                 1.000000           NaN           NaN          NaN   \n",
      "embarked_nan                    NaN           1.0           NaN          NaN   \n",
      "class_Second                    NaN           NaN       1.00000     0.536460   \n",
      "class_Third                     NaN           NaN       0.53646     1.000000   \n",
      "who_man                         NaN           NaN           NaN          NaN   \n",
      "who_woman                       NaN           NaN           NaN          NaN   \n",
      "embark_town_Queenstown          NaN           NaN           NaN          NaN   \n",
      "embark_town_Southampton    0.993565           NaN           NaN          NaN   \n",
      "alive_yes                       NaN           NaN           NaN          NaN   \n",
      "\n",
      "                          who_man  who_woman  embark_town_Queenstown  \\\n",
      "survived                 0.529158        NaN                     NaN   \n",
      "pclass                        NaN        NaN                     NaN   \n",
      "age                           NaN        NaN                     NaN   \n",
      "sibsp                         NaN        NaN                     NaN   \n",
      "parch                         NaN        NaN                     NaN   \n",
      "fare                          NaN        NaN                     NaN   \n",
      "adult_male               1.000000   0.797119                     NaN   \n",
      "alone                         NaN        NaN                     NaN   \n",
      "sex_male                 0.898154   0.887508                     NaN   \n",
      "embarked_Q                    NaN        NaN                     1.0   \n",
      "embarked_S                    NaN        NaN                     NaN   \n",
      "embarked_nan                  NaN        NaN                     NaN   \n",
      "class_Second                  NaN        NaN                     NaN   \n",
      "class_Third                   NaN        NaN                     NaN   \n",
      "who_man                  1.000000   0.797119                     NaN   \n",
      "who_woman                0.797119   1.000000                     NaN   \n",
      "embark_town_Queenstown        NaN        NaN                     1.0   \n",
      "embark_town_Southampton       NaN        NaN                     NaN   \n",
      "alive_yes                0.529158        NaN                     NaN   \n",
      "\n",
      "                         embark_town_Southampton  alive_yes  \n",
      "survived                                     NaN   1.000000  \n",
      "pclass                                       NaN        NaN  \n",
      "age                                          NaN        NaN  \n",
      "sibsp                                        NaN        NaN  \n",
      "parch                                        NaN        NaN  \n",
      "fare                                         NaN        NaN  \n",
      "adult_male                                   NaN   0.529158  \n",
      "alone                                        NaN        NaN  \n",
      "sex_male                                     NaN   0.516121  \n",
      "embarked_Q                                   NaN        NaN  \n",
      "embarked_S                              0.993565        NaN  \n",
      "embarked_nan                                 NaN        NaN  \n",
      "class_Second                                 NaN        NaN  \n",
      "class_Third                                  NaN        NaN  \n",
      "who_man                                      NaN   0.529158  \n",
      "who_woman                                    NaN        NaN  \n",
      "embark_town_Queenstown                       NaN        NaN  \n",
      "embark_town_Southampton                 1.000000        NaN  \n",
      "alive_yes                                    NaN   1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset (assuming df is already loaded)\n",
    "df_encoded = df.copy()  # Creating a copy to avoid modifying the original dataframe\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = df_encoded.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Convert categorical columns to string before encoding\n",
    "df_encoded[categorical_columns] = df_encoded[categorical_columns].astype(str)\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Convert boolean values (if any) to integers\n",
    "df_encoded = df_encoded.astype(float)\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"\\nCorrelation Matrix:\\n\", df_encoded.corr())\n",
    "\n",
    "# Finding highly correlated features (absolute correlation > 0.5)\n",
    "correlation_matrix = df_encoded.corr().abs()\n",
    "high_corr = correlation_matrix[correlation_matrix > 0.5]\n",
    "print(\"\\nHighly Correlated Features (Correlation > 0.5):\\n\", high_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9️⃣ Outlier Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers Detected in fare Using IQR:\n",
      "          fare\n",
      "27   263.0000\n",
      "31   146.5208\n",
      "34    82.1708\n",
      "52    76.7292\n",
      "61    80.0000\n",
      "..        ...\n",
      "829   80.0000\n",
      "835   83.1583\n",
      "849   89.1042\n",
      "856  164.8667\n",
      "879   83.1583\n",
      "\n",
      "[102 rows x 1 columns]\n",
      "\n",
      "Outliers Detected in age Using IQR:\n",
      "       age\n",
      "33   66.0\n",
      "54   65.0\n",
      "94   59.0\n",
      "96   71.0\n",
      "116  70.5\n",
      "170  61.0\n",
      "232  59.0\n",
      "252  62.0\n",
      "275  63.0\n",
      "280  65.0\n",
      "326  61.0\n",
      "366  60.0\n",
      "438  64.0\n",
      "456  65.0\n",
      "483  63.0\n",
      "493  71.0\n",
      "545  64.0\n",
      "570  62.0\n",
      "587  60.0\n",
      "625  61.0\n",
      "630  80.0\n",
      "672  70.0\n",
      "684  60.0\n",
      "694  60.0\n",
      "745  70.0\n",
      "829  62.0\n",
      "851  74.0\n",
      "\n",
      "Outliers Detected in Fare Using Z-score:\n",
      "          fare  fare_zscore\n",
      "27   263.0000     4.355573\n",
      "88   263.0000     4.355573\n",
      "118  247.5208     4.060025\n",
      "258  512.3292     9.116066\n",
      "299  247.5208     4.060025\n",
      "311  262.3750     4.343639\n",
      "341  263.0000     4.355573\n",
      "377  211.5000     3.372273\n",
      "380  227.5250     3.678241\n",
      "438  263.0000     4.355573\n",
      "527  221.7792     3.568535\n",
      "557  227.5250     3.678241\n",
      "679  512.3292     9.116066\n",
      "689  211.3375     3.369170\n",
      "700  227.5250     3.678241\n",
      "716  227.5250     3.678241\n",
      "730  211.3375     3.369170\n",
      "737  512.3292     9.116066\n",
      "742  262.3750     4.343639\n",
      "779  211.3375     3.369170\n"
     ]
    }
   ],
   "source": [
    "# Using IQR (Interquartile Range) method  \n",
    "for col in ['fare', 'age']:  \n",
    "    Q1 = df[col].quantile(0.25)  \n",
    "    Q3 = df[col].quantile(0.75)  \n",
    "    IQR = Q3 - Q1  \n",
    "    outliers_iqr = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))]  \n",
    "    print(f\"\\nOutliers Detected in {col} Using IQR:\\n\", outliers_iqr[[col]])  \n",
    "\n",
    "# Using Z-score method  \n",
    "df['fare_zscore'] = zscore(df['fare'])  \n",
    "outliers_z = df[df['fare_zscore'].abs() > 3]  \n",
    "print(\"\\nOutliers Detected in Fare Using Z-score:\\n\", outliers_z[['fare', 'fare_zscore']])  \n",
    "\n",
    "# Dropping the temporary Z-score column  \n",
    "df.drop(columns=['fare_zscore'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔟 Data Distribution Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skewness of age: 0.44198678493510685\n",
      "Kurtosis of age: 0.567323209153018\n",
      "\n",
      "Skewness of fare: 4.549950352869661\n",
      "Kurtosis of fare: 29.905898390901694\n",
      "\n",
      "Skewness of sibsp: 3.036078087580425\n",
      "Kurtosis of sibsp: 12.608665960050903\n",
      "\n",
      "Skewness of parch: 2.6133474892883943\n",
      "Kurtosis of parch: 8.837563410273624\n"
     ]
    }
   ],
   "source": [
    "# Checking skewness & kurtosis for numerical features  \n",
    "for col in numerical_features:  \n",
    "    print(f\"\\nSkewness of {col}: {df[col].skew()}\")  \n",
    "    print(f\"Kurtosis of {col}: {df[col].kurt()}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1️⃣1️⃣ Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Feature Summary:\n",
      "        family_size    is_alone\n",
      "count   775.000000  775.000000\n",
      "mean      1.949677    0.563871\n",
      "std       1.522882    0.496224\n",
      "min       1.000000    0.000000\n",
      "25%       1.000000    0.000000\n",
      "50%       1.000000    1.000000\n",
      "75%       2.000000    1.000000\n",
      "max      11.000000    1.000000\n",
      "\n",
      "Final Dataset Shape After EDA: (775, 16)\n"
     ]
    }
   ],
   "source": [
    "# Creating a new feature: Family Size  \n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1  \n",
    "\n",
    "# Creating a new binary feature: Is Alone?  \n",
    "df['is_alone'] = (df['family_size'] == 1).astype(int)  \n",
    "\n",
    "# Checking new feature distributions  \n",
    "print(\"\\nNew Feature Summary:\\n\", df[['family_size', 'is_alone']].describe())  \n",
    "\n",
    "## **🔚 Conclusion**\n",
    "print(\"\\nFinal Dataset Shape After EDA:\", df.shape)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
