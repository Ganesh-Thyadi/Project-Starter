{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformer-Based Models (BERT, Flair)**\n",
    "\n",
    "Transformer models like BERT and Flair use attention mechanisms to capture relationships in text for high-quality NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Pre-trained BERT for NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789f51afc6734c9f8e34cff0a93f9295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ch.K.Abhiram\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1ad5fbb0434b89b3e5b5cfa24ab283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c535542d59944db29e4e7b56ba8de442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d52f7624a54d5a856afa834cdb5ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332610f0ba8d4aaeb978eec96eae34b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf773b8975ba498c82ac22f88a9968e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NER Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.998917, 'index': 1, 'word': 'John', 'start': 0, 'end': 4}, {'entity': 'B-LOC', 'score': 0.99937576, 'index': 4, 'word': 'New', 'start': 14, 'end': 17}, {'entity': 'I-LOC', 'score': 0.999428, 'index': 5, 'word': 'York', 'start': 18, 'end': 22}]\n"
     ]
    }
   ],
   "source": [
    "text = \"John lives in New York.\"\n",
    "entities = ner_pipeline(text)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Boilerplate Code with Flair:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.15.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: boto3>=1.20.27 in c:\\python312\\lib\\site-packages (from flair) (1.36.3)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\python312\\lib\\site-packages (from flair) (1.2.18)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\python312\\lib\\site-packages (from flair) (0.28.0)\n",
      "Collecting langdetect>=1.0.9 (from flair)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 981.5/981.5 kB 5.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml>=4.8.0 (from flair)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\python312\\lib\\site-packages (from flair) (3.9.3)\n",
      "Collecting more-itertools>=8.13.0 (from flair)\n",
      "  Downloading more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from flair) (2.9.0.post0)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python312\\lib\\site-packages (from flair) (2024.11.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python312\\lib\\site-packages (from flair) (1.5.2)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\python312\\lib\\site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\python312\\lib\\site-packages (from flair) (2.6.0)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in c:\\python312\\lib\\site-packages (from flair) (4.66.5)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in c:\\python312\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.48.1)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.3 in c:\\python312\\lib\\site-packages (from boto3>=1.20.27->flair) (1.36.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\python312\\lib\\site-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\python312\\lib\\site-packages (from boto3>=1.20.27->flair) (0.11.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\python312\\lib\\site-packages (from deprecated>=1.2.13->flair) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ch.k.abhiram\\appdata\\roaming\\python\\python312\\site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from gdown>=4.4.0->flair) (3.17.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\python312\\lib\\site-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
      "Requirement already satisfied: six in c:\\python312\\lib\\site-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (4.55.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from mpld3>=0.3->flair) (3.1.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (3.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (74.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ch.k.abhiram\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.63.0->flair) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\python312\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
      "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.29.3)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\python312\\lib\\site-packages (from botocore<1.37.0,>=1.36.3->boto3>=1.20.27->flair) (2.2.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\python312\\lib\\site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (24.2.0)\n",
      "Collecting accelerate>=0.26.0 (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
      "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->mpld3>=0.3->flair) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.8.30)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.4.0->flair)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: psutil in c:\\python312\\lib\\site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.8)\n",
      "Downloading flair-0.15.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -------------------------------------- - 3.7/3.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993250 sha256=e1e708b5c7e7363ebf068084d288ba9478720fcbbd657104eaa325b41770c4de\n",
      "  Stored in directory: c:\\users\\ch.k.abhiram\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "  Building wheel for pptree (setup.py): started\n",
      "  Building wheel for pptree (setup.py): finished with status 'done'\n",
      "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4613 sha256=c662da1de7fdc6046e3f0c433803a28f4a016873dbc6327c90507dbcaff2bd24\n",
      "  Stored in directory: c:\\users\\ch.k.abhiram\\appdata\\local\\pip\\cache\\wheels\\b0\\2d\\de\\37058114a8f07cfec75747cb46b864bc5c71b0e9e0e4cd0acd\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16903 sha256=2a9b489c3a3aa43a70875299ca5e09391265d318fd65056d8d9591d47cfe4e17\n",
      "  Stored in directory: c:\\users\\ch.k.abhiram\\appdata\\local\\pip\\cache\\wheels\\7a\\6f\\21\\fc016aef45ffcabe27129a2252f061387cbf278d2086225a64\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15439 sha256=5ac750f6b406610f4cb2bceeb16fc401b81c1f6d859d91e9b1a259aec551e882\n",
      "  Stored in directory: c:\\users\\ch.k.abhiram\\appdata\\local\\pip\\cache\\wheels\\33\\3c\\79\\b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13776 sha256=51403781e45146c14bf9fa18105fff33c8ebaf6f3c8a2b727935e1a041b5c4da\n",
      "  Stored in directory: c:\\users\\ch.k.abhiram\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for intervaltree (setup.py): started\n",
      "  Building wheel for intervaltree (setup.py): finished with status 'done'\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26125 sha256=bcc35a805a01ab2af8ddd48d1c78e71917f9de0a4138ef51380e5bec963cdef8\n",
      "  Stored in directory: c:\\users\\ch.k.abhiram\\appdata\\local\\pip\\cache\\wheels\\65\\c3\\c3\\238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
      "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
      "Installing collected packages: sqlitedict, sortedcontainers, pptree, docopt, segtok, PySocks, more-itertools, lxml, langdetect, jsonlines, intervaltree, ftfy, conllu, wikipedia-api, bioc, pytorch-revgrad, mpld3, gdown, accelerate, transformer-smaller-training-vocab, flair\n",
      "Successfully installed PySocks-1.7.1 accelerate-1.3.0 bioc-2.1 conllu-4.5.3 docopt-0.6.2 flair-0.15.0 ftfy-6.3.1 gdown-5.2.0 intervaltree-3.1.0 jsonlines-4.0.0 langdetect-1.0.9 lxml-5.3.0 more-itertools-10.6.0 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 segtok-1.5.11 sortedcontainers-2.4.0 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "!pip install flair\n",
    "!pip install transformers  # Flair often uses transformers, so install it too (if you haven't already)\n",
    "\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Pre-trained Flair Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = SequenceTagger.load(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict Entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence(\"John lives in New York.\")\n",
    "tagger.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
