{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOvUfOyWUhpG"
   },
   "source": [
    "## **Capsule Networks**\n",
    "\n",
    "Capsule Networks (CapsNets) are designed to address some of the limitations of traditional convolutional neural networks (CNNs), such as their inability to capture spatial relationships between parts of an object. CapsNets use \"capsules,\" which are groups of neurons that represent the instantiation parameters of an object or part. These capsules are designed to work together in a way that allows the network to better capture hierarchical relationships and pose information, leading to more robust representations, especially for image recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1TWE0LxU_-E"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z7qDmaLvVEUv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3qgM8luVJcx"
   },
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N80pFaOVKtQ"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "input_data = torch.randn(batch_size, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0a24kpEVfIZ"
   },
   "source": [
    "**Capsule Network Layer Definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGdDRzYRViZE"
   },
   "outputs": [],
   "source": [
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_dim, out_dim, kernel_size=9, stride=1):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_routes = num_routes\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.capsules = nn.ModuleList([nn.Conv2d(in_dim, out_dim, kernel_size=kernel_size, stride=stride) \n",
    "                                      for _ in range(num_capsules)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        capsule_outputs = []\n",
    "        for capsule in self.capsules:\n",
    "            capsule_outputs.append(capsule(x))\n",
    "        capsule_outputs = torch.stack(capsule_outputs, dim=1)\n",
    "        return capsule_outputs\n",
    "\n",
    "class CapsuleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleNetwork, self).__init__()\n",
    "        # Input Conv Layer (Primary Capsule Layer)\n",
    "        self.conv1 = nn.Conv2d(1, 256, kernel_size=9)\n",
    "        self.primary_capsule = CapsuleLayer(num_capsules=8, num_routes=6, in_dim=256, out_dim=32, kernel_size=9, stride=2)\n",
    "        # Digit Capsule Layer\n",
    "        self.digit_capsule = CapsuleLayer(num_capsules=10, num_routes=8, in_dim=32, out_dim=16, kernel_size=9, stride=2)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.primary_capsule(x)\n",
    "        x = self.digit_capsule(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        decoded = self.decoder(x)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS5BfgpGVln2"
   },
   "source": [
    "**Instantiating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcjFFa-bVpkk"
   },
   "outputs": [],
   "source": [
    "model = CapsuleNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lJ3LJNlVuHt"
   },
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARqNM8R3Vynf"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_data)  # Forward pass\n",
    "    loss = criterion(output, input_data.view(batch_size, -1))  # Loss: Reconstruction Error\n",
    "    loss.backward()  # Backpropagate\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
