{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOvUfOyWUhpG"
   },
   "source": [
    "## **Scaled Dot-Product Attention**\n",
    "\n",
    "Scaled Dot-Product Attention is a form of attention where the attention scores are calculated as the dot product of the query and key, divided by the square root of the dimension of the key (scaling factor). This scaling helps to stabilize gradients during training. The attention scores are then passed through a softmax function to get the attention weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1TWE0LxU_-E"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z7qDmaLvVEUv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3qgM8luVJcx"
   },
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N80pFaOVKtQ"
   },
   "outputs": [],
   "source": [
    "query = torch.randn(1, 20)\n",
    "key = torch.randn(10, 20)\n",
    "value = torch.randn(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0a24kpEVfIZ"
   },
   "source": [
    "**Scaled Dot-Product Attention Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGdDRzYRViZE"
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # Compute the attention scores\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(self.input_dim)\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attention_weights, value)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS5BfgpGVln2"
   },
   "source": [
    "**Instantiate and Apply Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcjFFa-bVpkk"
   },
   "outputs": [],
   "source": [
    "scaled_dot_product_attention = ScaledDotProductAttention(input_dim=20)\n",
    "output, attention_weights = scaled_dot_product_attention(query, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lJ3LJNlVuHt"
   },
   "source": [
    "**Display Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARqNM8R3Vynf"
   },
   "outputs": [],
   "source": [
    "print(\"Scaled Dot-Product Attention Output:\", output)\n",
    "print(\"Attention Weights:\", attention_weights)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
